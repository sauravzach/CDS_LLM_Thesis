{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ3tJf1OUZ7l"
   },
   "source": [
    "# Prepare the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1686304706543,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "GJiluWpsqhlC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "def getpreferredencoding(do_setlocale = True):\n",
    "    return \"UTF-8\"\n",
    "locale.getpreferredencoding = getpreferredencoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.1)\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.41.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.66.4-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (8.1.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.8.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.4.127)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Collecting huggingface-hub<1.0,>=0.23.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers)\n",
      "  Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Downloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: comm>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (8.16.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (5.11.2)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /usr/local/lib/python3.10/dist-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (2.16.1)\n",
      "Requirement already satisfied: stack-data in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (1.1.3)\n",
      "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.8)\n",
      "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.0)\n",
      "Requirement already satisfied: pure-eval in /usr/local/lib/python3.10/dist-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Downloading transformers-4.41.0-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_learn-1.4.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading regex-2024.5.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (775 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m775.1/775.1 kB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.4.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m99.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m80.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tokenizers-0.19.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tqdm, threadpoolctl, scipy, safetensors, regex, joblib, scikit-learn, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed huggingface-hub-0.23.0 joblib-1.4.2 regex-2024.5.15 safetensors-0.4.3 scikit-learn-1.4.2 scipy-1.13.0 threadpoolctl-3.5.0 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch pandas transformers tqdm scikit-learn ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 1648,
     "status": "ok",
     "timestamp": 1686304708183,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "NQJBvotVTRaZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import XLNetConfig, XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import DataCollatorWithPadding\n",
    "import string\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tq\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d613f9ad-e57a-41de-a4c1-80ccbcba2084"
   },
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1686304929562,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "e9a8c3df-f130-4151-aa9e-1248c5abd104",
    "outputId": "e869a778-47a6-45fc-f42c-252184dd62e4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Reading the TSV files and verifying the number of rows\n",
    "# df_tweets = pd.read_table('./distorted vs non-distorted.tsv', encoding='utf-8')\n",
    "df_corpus = pd.read_csv('/kaggle/input/expertannotatedcdsdataset/train_sentences.tsv', delimiter='\\t', encoding='utf-8')\n",
    "\n",
    "print(f'Sentences count:               {df_corpus.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-15T16:25:56.519553Z",
     "iopub.status.busy": "2024-05-15T16:25:56.519190Z",
     "iopub.status.idle": "2024-05-15T16:25:56.529224Z",
     "shell.execute_reply": "2024-05-15T16:25:56.528188Z",
     "shell.execute_reply.started": "2024-05-15T16:25:56.519523Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1686304930587,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "l_844WFGmKrV",
    "outputId": "95455012-0889-4447-ea7e-8a8e04e7ef03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "non-distorted    4024\n",
       "distorted        1829\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corpus['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ONoG5PloVFT"
   },
   "source": [
    "# Split data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:25:57.584667Z",
     "iopub.status.busy": "2024-05-15T16:25:57.584264Z",
     "iopub.status.idle": "2024-05-15T16:25:57.596269Z",
     "shell.execute_reply": "2024-05-15T16:25:57.595203Z",
     "shell.execute_reply.started": "2024-05-15T16:25:57.584635Z"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1686304940218,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "wyn_Dt_MBFhp"
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df_corpus[\"sentence\"].values,\n",
    "    df_corpus[\"encoded_label\"].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df_corpus[\"encoded_label\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkrdipF1n_lt"
   },
   "source": [
    "# Generate the XLNet tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-15T16:25:58.747826Z",
     "iopub.status.busy": "2024-05-15T16:25:58.747195Z",
     "iopub.status.idle": "2024-05-15T16:26:13.186707Z",
     "shell.execute_reply": "2024-05-15T16:26:13.185429Z",
     "shell.execute_reply.started": "2024-05-15T16:25:58.747797Z"
    },
    "executionInfo": {
     "elapsed": 11733,
     "status": "ok",
     "timestamp": 1684239220281,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "S5NnRELvBZh3",
    "outputId": "78e0992f-ce3f-4209-aa59-f344b547b31c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.39.3)\n",
      "Requirement already satisfied: SentencePiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers SentencePiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "b303567f594a4dcdb8f8a4b7871b5f1f",
      "476d83b770df43aaab65ddb2f19cfbea",
      "748ede6f01e5467aa8ecd4f7f9ed1a41",
      "dfe5740731fc45c1acac705ac4ffb51e",
      "75c1666b0ece415d965949221a2bbf69",
      "f42d54b42cbf412b951eff37d59a654a",
      "bd43e611bdcf4f0ab893aaf6739c9005",
      "8d5fadf6f443469aa2df6f857c9e01f3",
      "d7aa808b6fa7408d926bace8a5a20871",
      "00311f23548146b6a868fb84d0642e72",
      "063969e5a4a948b7ae0993b40b7172d8",
      "0218acd61f5a40238d341c4d429c0426",
      "c682728d8aee46d89975bd8b4c918b39",
      "91098b7a20f148829d449f93972c534b",
      "893e19f50398497ba8e9ed520889552f",
      "dee7bcda2fb746b7976f8be55f36f8c4",
      "87a58caac2dd42049ae469c1c2d41156",
      "efa04f9d0e1d4c2e8aed2b2ceaef4822",
      "bc37351c51614909aadb2158143afc11",
      "5483a21e1fe34348af5ff1167ade0ce9",
      "b04853982603480bbaa1b5c8d8df223f",
      "886b8d44555e4d30a3141126816b719c"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-05-15T16:26:13.189349Z",
     "iopub.status.busy": "2024-05-15T16:26:13.189028Z",
     "iopub.status.idle": "2024-05-15T16:26:14.199616Z",
     "shell.execute_reply": "2024-05-15T16:26:14.198553Z",
     "shell.execute_reply.started": "2024-05-15T16:26:13.189321Z"
    },
    "executionInfo": {
     "elapsed": 2437,
     "status": "ok",
     "timestamp": 1684239228973,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "XDtYiTTZB6Q_",
    "outputId": "5b15e06e-36f5-4862-aeba-05fa687867f4"
   },
   "outputs": [],
   "source": [
    "# Load XLNet tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:26:14.201291Z",
     "iopub.status.busy": "2024-05-15T16:26:14.200958Z",
     "iopub.status.idle": "2024-05-15T16:26:14.206073Z",
     "shell.execute_reply": "2024-05-15T16:26:14.204843Z",
     "shell.execute_reply.started": "2024-05-15T16:26:14.201264Z"
    },
    "id": "snlNfiZhrPwI"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 128 # This is important as it is basically the context length and also decides how much GPU is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c193e633fbe74e8ca02fbb5d5698e91d",
      "3a04454dd09f411d9295310f586d9b7b",
      "7f1ddf2d605d41e3b88eaca5887276be",
      "2734421d7d6a4afdb6bcdc5b0af3b1a3",
      "d98a8428ca8d4895a4bf6554c9d17b7b",
      "1fe64aa00d3d4f8d8f4ad1d7b98937b2",
      "a68adc6f867d4f83a2f7d82eda675114",
      "d3278c6f7fce455bbd7d6118da98aac8",
      "aa1a67bdaf3e4cf9aaebef8c9386ca5b",
      "43ad42ee313c4f2bac1af2e72b8db4d0",
      "04a7c90c402142079bec4883167f0d8a"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-05-15T16:26:14.209061Z",
     "iopub.status.busy": "2024-05-15T16:26:14.208683Z",
     "iopub.status.idle": "2024-05-15T16:26:16.731967Z",
     "shell.execute_reply": "2024-05-15T16:26:16.730958Z",
     "shell.execute_reply.started": "2024-05-15T16:26:14.209035Z"
    },
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1684239230786,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "iao77PSPrD0Z",
    "outputId": "8c68578c-81de-4bfb-d7f0-2ae7703edada"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42cee216eeeb4297a9f7d08b7e9f86f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5267 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the training set\n",
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "for text in tqdm(train_texts):\n",
    "    encoded_dict = tokenizer.encode_plus(text,\n",
    "                                         max_length=max_seq_length,\n",
    "                                         add_special_tokens=True,\n",
    "                                         truncation=True,\n",
    "                                         padding='max_length',\n",
    "                                         return_attention_mask=True,\n",
    "                                         return_tensors='pt')\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:26:16.733627Z",
     "iopub.status.busy": "2024-05-15T16:26:16.733308Z",
     "iopub.status.idle": "2024-05-15T16:26:16.761168Z",
     "shell.execute_reply": "2024-05-15T16:26:16.759960Z",
     "shell.execute_reply.started": "2024-05-15T16:26:16.733600Z"
    },
    "id": "psYu3CJZruuU"
   },
   "outputs": [],
   "source": [
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:26:16.763399Z",
     "iopub.status.busy": "2024-05-15T16:26:16.762691Z",
     "iopub.status.idle": "2024-05-15T16:26:16.792254Z",
     "shell.execute_reply": "2024-05-15T16:26:16.791206Z",
     "shell.execute_reply.started": "2024-05-15T16:26:16.763363Z"
    },
    "id": "gPzgDcOsN2I0"
   },
   "outputs": [],
   "source": [
    "torch.save(train_input_ids, './train_input_ids.pt')\n",
    "torch.save(train_attention_masks, './train_attention_masks.pt')\n",
    "torch.save(train_labels, './train_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "88b6262432f6429db0553c901e82e88e",
      "d3250d7e34644f6ca284376fdc850db5",
      "9f1f694f802a4e7f83725b3f6540f8ca",
      "b51b67a1f2b54a05ac84c02fd87b4dc8",
      "43968ef17ce94afc8f2f3e43ea465352",
      "e1b7668e6cae4706ad989273f33b8129",
      "3b96027dff0d4c38aa76ffc45659152a",
      "de94ad0aa2194e238149528472ab784f",
      "0c210400b3e1489ab4fda881e0207ec4",
      "0b8df0579bac470f8f2c6b0f2c002e9a",
      "55c26b04b8644ad99b03f20e01cdb82d"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:21.665806Z",
     "iopub.status.busy": "2024-05-12T17:57:21.665200Z",
     "iopub.status.idle": "2024-05-12T17:57:21.938550Z",
     "shell.execute_reply": "2024-05-12T17:57:21.937574Z",
     "shell.execute_reply.started": "2024-05-12T17:57:21.665771Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684239233460,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "soiNyZ9FjfIw",
    "outputId": "2509e8fb-d568-4344-93df-58d63f49d75e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eddb4bcdca540c39971a82b1c43d843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/586 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the validation set\n",
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "for text in tqdm(val_texts):\n",
    "    encoded_dict = tokenizer.encode_plus(text,\n",
    "                                         max_length=max_seq_length,\n",
    "                                         add_special_tokens=True,\n",
    "                                         truncation=True,\n",
    "                                         padding='max_length',\n",
    "                                         return_attention_mask=True,\n",
    "                                         return_tensors='pt')\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:21.940111Z",
     "iopub.status.busy": "2024-05-12T17:57:21.939810Z",
     "iopub.status.idle": "2024-05-12T17:57:21.947187Z",
     "shell.execute_reply": "2024-05-12T17:57:21.946220Z",
     "shell.execute_reply.started": "2024-05-12T17:57:21.940086Z"
    },
    "id": "0Mo5uKOJsAZQ"
   },
   "outputs": [],
   "source": [
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "val_labels = torch.tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:21.948934Z",
     "iopub.status.busy": "2024-05-12T17:57:21.948583Z",
     "iopub.status.idle": "2024-05-12T17:57:21.959235Z",
     "shell.execute_reply": "2024-05-12T17:57:21.958228Z",
     "shell.execute_reply.started": "2024-05-12T17:57:21.948907Z"
    },
    "id": "nJOa5eM0xI3K"
   },
   "outputs": [],
   "source": [
    "# Save the tensors to files\n",
    "torch.save(val_input_ids, './val_input_ids.pt')\n",
    "torch.save(val_attention_masks, './val_attention_masks.pt')\n",
    "torch.save(val_labels, './val_labels.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for training XLNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:35:15.834048Z",
     "iopub.status.busy": "2024-05-15T15:35:15.833592Z",
     "iopub.status.idle": "2024-05-15T15:35:15.840601Z",
     "shell.execute_reply": "2024-05-15T15:35:15.839452Z",
     "shell.execute_reply.started": "2024-05-15T15:35:15.834015Z"
    },
    "id": "oPi51JAlN-OS"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:21.972178Z",
     "iopub.status.busy": "2024-05-12T17:57:21.971599Z",
     "iopub.status.idle": "2024-05-12T17:57:25.555329Z",
     "shell.execute_reply": "2024-05-12T17:57:25.554401Z",
     "shell.execute_reply.started": "2024-05-12T17:57:21.972144Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2215d447caa94c41a5f1d5fd72c5c391",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=2)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:25.557187Z",
     "iopub.status.busy": "2024-05-12T17:57:25.556749Z",
     "iopub.status.idle": "2024-05-12T17:57:25.567154Z",
     "shell.execute_reply": "2024-05-12T17:57:25.566179Z",
     "shell.execute_reply.started": "2024-05-12T17:57:25.557153Z"
    }
   },
   "outputs": [],
   "source": [
    "train_input_ids = torch.load('./train_input_ids.pt')\n",
    "train_attention_masks = torch.load('./train_attention_masks.pt')\n",
    "train_labels = torch.load('./train_labels.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:25.568728Z",
     "iopub.status.busy": "2024-05-12T17:57:25.568378Z",
     "iopub.status.idle": "2024-05-12T17:57:25.575210Z",
     "shell.execute_reply": "2024-05-12T17:57:25.574385Z",
     "shell.execute_reply.started": "2024-05-12T17:57:25.568696Z"
    }
   },
   "outputs": [],
   "source": [
    "val_input_ids = torch.load('./val_input_ids.pt')\n",
    "val_attention_masks = torch.load('./val_attention_masks.pt')\n",
    "val_labels = torch.load('./val_labels.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the XLNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:30:58.117746Z",
     "iopub.status.busy": "2024-05-15T15:30:58.117189Z",
     "iopub.status.idle": "2024-05-15T15:30:58.224119Z",
     "shell.execute_reply": "2024-05-15T15:30:58.223140Z",
     "shell.execute_reply.started": "2024-05-15T15:30:58.117711Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the input_ids, attention_masks, and label tensors for the given index\n",
    "        input_id = self.input_ids[idx]\n",
    "        attention_mask = self.attention_masks[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_id,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:25.587212Z",
     "iopub.status.busy": "2024-05-12T17:57:25.586695Z",
     "iopub.status.idle": "2024-05-12T17:57:25.595350Z",
     "shell.execute_reply": "2024-05-12T17:57:25.594527Z",
     "shell.execute_reply.started": "2024-05-12T17:57:25.587186Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a TensorDataset from the encoded texts and labels\n",
    "train_dataset = MyDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "val_dataset = MyDataset(val_input_ids,val_attention_masks, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:25.596700Z",
     "iopub.status.busy": "2024-05-12T17:57:25.596412Z",
     "iopub.status.idle": "2024-05-12T17:57:25.675136Z",
     "shell.execute_reply": "2024-05-12T17:57:25.674295Z",
     "shell.execute_reply.started": "2024-05-12T17:57:25.596676Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    evaluation_strategy=\"epoch\",     # evaluate and save checkpoint every epoch\n",
    "    learning_rate=2e-5,              # learning rate\n",
    "    per_device_train_batch_size=32, # batch size per device during training\n",
    "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
    "    num_train_epochs=5,              # total number of training epochs\n",
    "    warmup_steps=0,                  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    "    logging_steps=10,              # log after every n steps\n",
    "    save_total_limit=5,              # number of total models to save\n",
    "    save_strategy='epoch',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:25.679622Z",
     "iopub.status.busy": "2024-05-12T17:57:25.679324Z",
     "iopub.status.idle": "2024-05-12T17:57:26.554883Z",
     "shell.execute_reply": "2024-05-12T17:57:26.554116Z",
     "shell.execute_reply.started": "2024-05-12T17:57:25.679598Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T17:57:26.556127Z",
     "iopub.status.busy": "2024-05-12T17:57:26.555849Z",
     "iopub.status.idle": "2024-05-12T18:04:55.799588Z",
     "shell.execute_reply": "2024-05-12T18:04:55.798789Z",
     "shell.execute_reply.started": "2024-05-12T17:57:26.556102Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/kaggle/working/wandb/run-20240512_175737-2s9gmcls</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/deeplearningteammaastricht/huggingface/runs/2s9gmcls' target=\"_blank\">restful-surf-6</a></strong> to <a href='https://wandb.ai/deeplearningteammaastricht/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/deeplearningteammaastricht/huggingface' target=\"_blank\">https://wandb.ai/deeplearningteammaastricht/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/deeplearningteammaastricht/huggingface/runs/2s9gmcls' target=\"_blank\">https://wandb.ai/deeplearningteammaastricht/huggingface/runs/2s9gmcls</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='825' max='825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [825/825 06:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.180592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.080300</td>\n",
       "      <td>0.195293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.020200</td>\n",
       "      <td>0.244298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.265989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.281111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=825, training_loss=0.08275071759990445, metrics={'train_runtime': 448.8445, 'train_samples_per_second': 58.673, 'train_steps_per_second': 1.838, 'total_flos': 1875580540500480.0, 'train_loss': 0.08275071759990445, 'epoch': 5.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model \n",
    "# WANDB API c07df26de2fdda62ae6c5019d4fe7dfd6aad0cc2\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:49:41.167149Z",
     "iopub.status.busy": "2024-05-15T15:49:41.166792Z",
     "iopub.status.idle": "2024-05-15T15:49:41.215445Z",
     "shell.execute_reply": "2024-05-15T15:49:41.214092Z",
     "shell.execute_reply.started": "2024-05-15T15:49:41.167123Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "eval_result = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:04:55.800976Z",
     "iopub.status.busy": "2024-05-12T18:04:55.800699Z",
     "iopub.status.idle": "2024-05-12T18:04:56.848757Z",
     "shell.execute_reply": "2024-05-12T18:04:56.847616Z",
     "shell.execute_reply.started": "2024-05-12T18:04:55.800951Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May 12 18:04:56 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   68C    P0              43W / 250W |   5688MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T18:05:01.807738Z",
     "iopub.status.busy": "2024-05-12T18:05:01.807213Z",
     "iopub.status.idle": "2024-05-12T18:05:02.755711Z",
     "shell.execute_reply": "2024-05-12T18:05:02.754385Z",
     "shell.execute_reply.started": "2024-05-12T18:05:01.807702Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./Final Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train from checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:03:43.450544Z",
     "iopub.status.busy": "2024-05-17T17:03:43.449901Z",
     "iopub.status.idle": "2024-05-17T17:03:43.458185Z",
     "shell.execute_reply": "2024-05-17T17:03:43.457273Z",
     "shell.execute_reply.started": "2024-05-17T17:03:43.450508Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import XLNetConfig, XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import DataCollatorWithPadding\n",
    "import string\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tq\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:03:48.198444Z",
     "iopub.status.busy": "2024-05-17T17:03:48.197790Z",
     "iopub.status.idle": "2024-05-17T17:03:48.208926Z",
     "shell.execute_reply": "2024-05-17T17:03:48.207983Z",
     "shell.execute_reply.started": "2024-05-17T17:03:48.198411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/results/checkpoint-825'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Set the path to the directory containing the checkpoint folders\n",
    "checkpoint_dir = '/kaggle/working/results/'\n",
    "\n",
    "# Get a list of all the checkpoint folders in the directory\n",
    "checkpoint_folders = [f for f in os.listdir(checkpoint_dir) if re.match(r'checkpoint-\\d+', f)]\n",
    "\n",
    "# Sort the checkpoint folders by the numerical suffix\n",
    "checkpoint_folders.sort(key=lambda x: int(x.split('-')[-1]))\n",
    "\n",
    "# Get the latest checkpoint folder name\n",
    "latest_checkpoint_folder = os.path.join(checkpoint_dir, checkpoint_folders[-1])\n",
    "\n",
    "# Set the path to the checkpoint directory\n",
    "checkpoint_path = latest_checkpoint_folder\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-12T18:04:57.907999Z",
     "iopub.status.idle": "2024-05-12T18:04:57.908517Z",
     "shell.execute_reply": "2024-05-12T18:04:57.908272Z",
     "shell.execute_reply.started": "2024-05-12T18:04:57.908251Z"
    }
   },
   "outputs": [],
   "source": [
    "# tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "# model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels=13)\n",
    "# optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "# training_args = TrainingArguments(\n",
    "#     output_dir='./results',\n",
    "#     evaluation_strategy=\"epoch\",\n",
    "#     learning_rate=2e-5,\n",
    "#     per_device_train_batch_size=128,\n",
    "#     per_device_eval_batch_size=128,\n",
    "#     num_train_epochs=3,\n",
    "#     warmup_steps=0,\n",
    "#     weight_decay=0.01,\n",
    "#     logging_dir='./logs',\n",
    "#     logging_steps=1000,\n",
    "#     save_total_limit=3,\n",
    "#     save_strategy='steps',\n",
    "#     save_steps=1000,\n",
    "#     resume_from_checkpoint=checkpoint_path\n",
    "# )\n",
    "\n",
    "# trainer = Trainer(\n",
    "#     model=model,\n",
    "#     args=training_args,\n",
    "#     train_dataset=train_dataset,\n",
    "#     eval_dataset=val_dataset,\n",
    "#     data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-12T18:04:57.909655Z",
     "iopub.status.idle": "2024-05-12T18:04:57.910116Z",
     "shell.execute_reply": "2024-05-12T18:04:57.909899Z",
     "shell.execute_reply.started": "2024-05-12T18:04:57.909878Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Call the train method to resume training\n",
    "# trainer.train(resume_from_checkpoint = True)\n",
    "# # trainer.train('/content/drive/MyDrive/01 - Thesis/XLNet fine-tuning/results_backup_20230226/checkpoint-19000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-12T18:04:57.911947Z",
     "iopub.status.idle": "2024-05-12T18:04:57.912470Z",
     "shell.execute_reply": "2024-05-12T18:04:57.912226Z",
     "shell.execute_reply.started": "2024-05-12T18:04:57.912205Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:04:20.169321Z",
     "iopub.status.busy": "2024-05-17T17:04:20.168333Z",
     "iopub.status.idle": "2024-05-17T17:04:20.433060Z",
     "shell.execute_reply": "2024-05-17T17:04:20.432054Z",
     "shell.execute_reply.started": "2024-05-17T17:04:20.169283Z"
    }
   },
   "outputs": [],
   "source": [
    "model = XLNetForSequenceClassification.from_pretrained('/kaggle/working/Final Model', num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T15:38:28.459877Z",
     "iopub.status.busy": "2024-05-15T15:38:28.459515Z",
     "iopub.status.idle": "2024-05-15T15:38:28.506579Z",
     "shell.execute_reply": "2024-05-15T15:38:28.505322Z",
     "shell.execute_reply.started": "2024-05-15T15:38:28.459847Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m eval_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "eval_result = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:04:24.966060Z",
     "iopub.status.busy": "2024-05-17T17:04:24.965682Z",
     "iopub.status.idle": "2024-05-17T17:04:24.970458Z",
     "shell.execute_reply": "2024-05-17T17:04:24.969260Z",
     "shell.execute_reply.started": "2024-05-17T17:04:24.966029Z"
    }
   },
   "outputs": [],
   "source": [
    "label_encoding = {'non-distorted':0,\n",
    "'distorted':1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:04:25.332332Z",
     "iopub.status.busy": "2024-05-17T17:04:25.331941Z",
     "iopub.status.idle": "2024-05-17T17:04:26.629377Z",
     "shell.execute_reply": "2024-05-17T17:04:26.628492Z",
     "shell.execute_reply.started": "2024-05-17T17:04:25.332301Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 1\n"
     ]
    }
   ],
   "source": [
    "# Input text\n",
    "input_text = \"I am the only one who wants to see Bolt play football.\"\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "# Tokenize input text\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=True, return_tensors=\"pt\")\n",
    "\n",
    "# Move input tensor to the same device as the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_ids = input_ids.to(device)\n",
    "model = model.to(device)\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    outputs = model(input_ids)\n",
    "\n",
    "# Extract predicted label\n",
    "_, predicted_label = torch.max(outputs[0], dim=1)\n",
    "\n",
    "print(\"Predicted label:\", predicted_label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T16:01:07.079487Z",
     "iopub.status.busy": "2024-05-15T16:01:07.078560Z",
     "iopub.status.idle": "2024-05-15T16:01:11.052829Z",
     "shell.execute_reply": "2024-05-15T16:01:11.051809Z",
     "shell.execute_reply.started": "2024-05-15T16:01:07.079443Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       403\n",
      "           1       0.94      0.91      0.93       183\n",
      "\n",
      "    accuracy                           0.95       586\n",
      "   macro avg       0.95      0.94      0.95       586\n",
      "weighted avg       0.95      0.95      0.95       586\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the saved tensors\n",
    "val_input_ids = torch.load('./val_input_ids.pt')\n",
    "val_attention_masks = torch.load('./val_attention_masks.pt')\n",
    "val_labels = torch.load('./val_labels.pt')\n",
    "\n",
    "# Move tensors and model to the same device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "val_input_ids = val_input_ids.to(device)\n",
    "val_attention_masks = val_attention_masks.to(device)\n",
    "val_labels = val_labels.to(device)\n",
    "model = model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Disable gradient computation to save memory\n",
    "with torch.no_grad():\n",
    "    outputs = model(val_input_ids, attention_mask=val_attention_masks)\n",
    "    logits = outputs[0]\n",
    "\n",
    "# Get the predicted labels\n",
    "predicted_labels = torch.argmax(logits, dim=1)\n",
    "\n",
    "# Move predicted labels and true labels to CPU for evaluation\n",
    "predicted_labels = predicted_labels.cpu().numpy()\n",
    "true_labels = val_labels.cpu().numpy()\n",
    "\n",
    "# Compute confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Display confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(true_labels, predicted_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:07:01.485894Z",
     "iopub.status.busy": "2024-05-17T17:07:01.485242Z",
     "iopub.status.idle": "2024-05-17T17:07:01.729297Z",
     "shell.execute_reply": "2024-05-17T17:07:01.728027Z",
     "shell.execute_reply.started": "2024-05-17T17:07:01.485862Z"
    }
   },
   "outputs": [
    {
     "ename": "IsADirectoryError",
     "evalue": "[Errno 21] Is a directory: '/kaggle/working/results/checkpoint-825'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m checkpoint \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(checkpoint\u001b[38;5;241m.\u001b[39mkeys())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/kaggle/working/results/checkpoint-825'"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "\n",
    "# checkpoint = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "# print(checkpoint.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:20:23.676340Z",
     "iopub.status.busy": "2024-05-17T17:20:23.675699Z",
     "iopub.status.idle": "2024-05-17T17:20:23.724054Z",
     "shell.execute_reply": "2024-05-17T17:20:23.723176Z",
     "shell.execute_reply.started": "2024-05-17T17:20:23.676305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2530, 5)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to the CSV file\n",
    "file_path = r\"/kaggle/input/expertannotatedcdsdataset/Annotated_data.csv\"\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "# Keep only the desired columns\n",
    "df = df[[\"Id_Number\", \"Distorted part\",\"Patient Question\", \"Dominant Distortion\", \"Secondary Distortion (Optional)\"]]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T17:20:26.587680Z",
     "iopub.status.busy": "2024-05-17T17:20:26.586840Z",
     "iopub.status.idle": "2024-05-17T17:20:26.595759Z",
     "shell.execute_reply": "2024-05-17T17:20:26.594794Z",
     "shell.execute_reply.started": "2024-05-17T17:20:26.587645Z"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1686304930587,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "l_844WFGmKrV",
    "outputId": "95455012-0889-4447-ea7e-8a8e04e7ef03"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dominant Distortion\n",
       "No Distortion              933\n",
       "Overgeneralization         239\n",
       "Mind Reading               239\n",
       "Magnification              195\n",
       "Labeling                   165\n",
       "Personalization            153\n",
       "Fortune-telling            143\n",
       "Emotional Reasoning        134\n",
       "Mental filter              122\n",
       "Should statements          107\n",
       "All-or-nothing thinking    100\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Dominant Distortion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:21:37.115696Z",
     "iopub.status.busy": "2024-05-17T17:21:37.115318Z",
     "iopub.status.idle": "2024-05-17T17:21:37.130689Z",
     "shell.execute_reply": "2024-05-17T17:21:37.129386Z",
     "shell.execute_reply.started": "2024-05-17T17:21:37.115669Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Id_Number                                     Distorted part  \\\n",
      "0          4500  The voice are always fimilar (someone she know...   \n",
      "1          4501  I feel trapped inside my disgusting self and l...   \n",
      "2          4502   So I’ve been dating on and off this guy for a...   \n",
      "3          4503  My parents got divorced in 2004. My mother has...   \n",
      "4          4504  I refused to go because I didn’t know if it wa...   \n",
      "...         ...                                                ...   \n",
      "2525       2562  I’m a 21 year old female. I spent most of my l...   \n",
      "2526       2563  Now I am at university my peers around me all ...   \n",
      "2527       2564  He claims he’s severely depressed and has outb...   \n",
      "2528       2565  From the U.S.: I am a 21 year old woman who ha...   \n",
      "2529       2568  I recently moved out on my ex-roommate because...   \n",
      "\n",
      "                                       Patient Question Dominant Distortion  \\\n",
      "0     Hello, I have a beautiful,smart,outgoing and a...     Personalization   \n",
      "1     Since I was about 16 years old I’ve had these ...            Labeling   \n",
      "2      So I’ve been dating on and off this guy for a...       No Distortion   \n",
      "3     My parents got divorced in 2004. My mother has...       No Distortion   \n",
      "4     I don’t really know how to explain the situati...     Fortune-telling   \n",
      "...                                                 ...                 ...   \n",
      "2525  I’m a 21 year old female. I spent most of my l...       No Distortion   \n",
      "2526  I am 21 female and have not had any friends fo...  Overgeneralization   \n",
      "2527  From the U.S.: My brother is 19 years old and ...       Mental filter   \n",
      "2528  From the U.S.: I am a 21 year old woman who ha...       No Distortion   \n",
      "2529  I recently moved out on my ex-roommate because...       No Distortion   \n",
      "\n",
      "     Secondary Distortion (Optional)  \n",
      "0                                NaN  \n",
      "1                Emotional Reasoning  \n",
      "2                                NaN  \n",
      "3                                NaN  \n",
      "4                Emotional Reasoning  \n",
      "...                              ...  \n",
      "2525                             NaN  \n",
      "2526                             NaN  \n",
      "2527                    Mind Reading  \n",
      "2528                             NaN  \n",
      "2529                             NaN  \n",
      "\n",
      "[2530 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "df.loc[df['Dominant Distortion'] == 'No Distortion', 'Distorted part'] = df['Patient Question']\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:21:52.721312Z",
     "iopub.status.busy": "2024-05-17T17:21:52.720120Z",
     "iopub.status.idle": "2024-05-17T17:21:52.732283Z",
     "shell.execute_reply": "2024-05-17T17:21:52.731132Z",
     "shell.execute_reply.started": "2024-05-17T17:21:52.721269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Personalization': 0,\n",
       " 'Labeling': 1,\n",
       " 'No Distortion': 2,\n",
       " 'Fortune-telling': 3,\n",
       " 'Magnification': 4,\n",
       " 'Mind Reading': 5,\n",
       " 'All-or-nothing thinking': 6,\n",
       " 'Overgeneralization': 7,\n",
       " 'Mental filter': 8,\n",
       " 'Emotional Reasoning': 9,\n",
       " 'Should statements': 10}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_distortions = pd.concat([df['Dominant Distortion']])\n",
    "\n",
    "distortion_to_id = {distortion: i for i, distortion in enumerate(all_distortions.dropna().unique())}\n",
    "distortion_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:21:54.647358Z",
     "iopub.status.busy": "2024-05-17T17:21:54.646737Z",
     "iopub.status.idle": "2024-05-17T17:21:54.657768Z",
     "shell.execute_reply": "2024-05-17T17:21:54.656852Z",
     "shell.execute_reply.started": "2024-05-17T17:21:54.647323Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dominant Distortion Encoded\n",
       "2     933\n",
       "7     239\n",
       "5     239\n",
       "4     195\n",
       "1     165\n",
       "0     153\n",
       "3     143\n",
       "9     134\n",
       "8     122\n",
       "10    107\n",
       "6     100\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Dominant Distortion Encoded'] = df['Dominant Distortion'].map(distortion_to_id).astype(pd.Int64Dtype())\n",
    "df['Dominant Distortion Encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:21:57.562140Z",
     "iopub.status.busy": "2024-05-17T17:21:57.561306Z",
     "iopub.status.idle": "2024-05-17T17:21:57.568677Z",
     "shell.execute_reply": "2024-05-17T17:21:57.567804Z",
     "shell.execute_reply.started": "2024-05-17T17:21:57.562107Z"
    }
   },
   "outputs": [],
   "source": [
    "num_labels = len(distortion_to_id)\n",
    "df = df.dropna(subset=[\"Distorted part\", \"Dominant Distortion Encoded\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:22:01.927962Z",
     "iopub.status.busy": "2024-05-17T17:22:01.927171Z",
     "iopub.status.idle": "2024-05-17T17:22:01.935759Z",
     "shell.execute_reply": "2024-05-17T17:22:01.934868Z",
     "shell.execute_reply.started": "2024-05-17T17:22:01.927932Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dominant Distortion Encoded\n",
       "2     933\n",
       "7     239\n",
       "5     239\n",
       "4     195\n",
       "1     165\n",
       "0     153\n",
       "3     143\n",
       "9     134\n",
       "8     122\n",
       "10    107\n",
       "6     100\n",
       "Name: count, dtype: Int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Dominant Distortion Encoded'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ONoG5PloVFT"
   },
   "source": [
    "# Split data into training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:22:14.258008Z",
     "iopub.status.busy": "2024-05-17T17:22:14.257087Z",
     "iopub.status.idle": "2024-05-17T17:22:14.267496Z",
     "shell.execute_reply": "2024-05-17T17:22:14.266331Z",
     "shell.execute_reply.started": "2024-05-17T17:22:14.257972Z"
    },
    "executionInfo": {
     "elapsed": 421,
     "status": "ok",
     "timestamp": 1686304940218,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "wyn_Dt_MBFhp"
   },
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
    "    df[\"Distorted part\"].values,\n",
    "    df[\"Dominant Distortion Encoded\"].values,\n",
    "    test_size=0.1,\n",
    "    random_state=42,\n",
    "    stratify=df[\"Dominant Distortion Encoded\"].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FkrdipF1n_lt"
   },
   "source": [
    "# Generate the XLNet tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "b303567f594a4dcdb8f8a4b7871b5f1f",
      "476d83b770df43aaab65ddb2f19cfbea",
      "748ede6f01e5467aa8ecd4f7f9ed1a41",
      "dfe5740731fc45c1acac705ac4ffb51e",
      "75c1666b0ece415d965949221a2bbf69",
      "f42d54b42cbf412b951eff37d59a654a",
      "bd43e611bdcf4f0ab893aaf6739c9005",
      "8d5fadf6f443469aa2df6f857c9e01f3",
      "d7aa808b6fa7408d926bace8a5a20871",
      "00311f23548146b6a868fb84d0642e72",
      "063969e5a4a948b7ae0993b40b7172d8",
      "0218acd61f5a40238d341c4d429c0426",
      "c682728d8aee46d89975bd8b4c918b39",
      "91098b7a20f148829d449f93972c534b",
      "893e19f50398497ba8e9ed520889552f",
      "dee7bcda2fb746b7976f8be55f36f8c4",
      "87a58caac2dd42049ae469c1c2d41156",
      "efa04f9d0e1d4c2e8aed2b2ceaef4822",
      "bc37351c51614909aadb2158143afc11",
      "5483a21e1fe34348af5ff1167ade0ce9",
      "b04853982603480bbaa1b5c8d8df223f",
      "886b8d44555e4d30a3141126816b719c"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T17:22:18.128034Z",
     "iopub.status.busy": "2024-05-17T17:22:18.127116Z",
     "iopub.status.idle": "2024-05-17T17:22:18.767768Z",
     "shell.execute_reply": "2024-05-17T17:22:18.766722Z",
     "shell.execute_reply.started": "2024-05-17T17:22:18.127991Z"
    },
    "executionInfo": {
     "elapsed": 2437,
     "status": "ok",
     "timestamp": 1684239228973,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "XDtYiTTZB6Q_",
    "outputId": "5b15e06e-36f5-4862-aeba-05fa687867f4"
   },
   "outputs": [],
   "source": [
    "# Load XLNet tokenizer\n",
    "tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:32.537255Z",
     "iopub.status.busy": "2024-05-17T17:25:32.536901Z",
     "iopub.status.idle": "2024-05-17T17:25:32.542895Z",
     "shell.execute_reply": "2024-05-17T17:25:32.541880Z",
     "shell.execute_reply.started": "2024-05-17T17:25:32.537230Z"
    },
    "id": "snlNfiZhrPwI"
   },
   "outputs": [],
   "source": [
    "max_seq_length = 64 # This is important as it is basically the context length and also decides how much GPU is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c193e633fbe74e8ca02fbb5d5698e91d",
      "3a04454dd09f411d9295310f586d9b7b",
      "7f1ddf2d605d41e3b88eaca5887276be",
      "2734421d7d6a4afdb6bcdc5b0af3b1a3",
      "d98a8428ca8d4895a4bf6554c9d17b7b",
      "1fe64aa00d3d4f8d8f4ad1d7b98937b2",
      "a68adc6f867d4f83a2f7d82eda675114",
      "d3278c6f7fce455bbd7d6118da98aac8",
      "aa1a67bdaf3e4cf9aaebef8c9386ca5b",
      "43ad42ee313c4f2bac1af2e72b8db4d0",
      "04a7c90c402142079bec4883167f0d8a"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:34.186753Z",
     "iopub.status.busy": "2024-05-17T17:25:34.186356Z",
     "iopub.status.idle": "2024-05-17T17:25:36.113671Z",
     "shell.execute_reply": "2024-05-17T17:25:36.110228Z",
     "shell.execute_reply.started": "2024-05-17T17:25:34.186722Z"
    },
    "executionInfo": {
     "elapsed": 1819,
     "status": "ok",
     "timestamp": 1684239230786,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "iao77PSPrD0Z",
    "outputId": "8c68578c-81de-4bfb-d7f0-2ae7703edada"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c665aed44e4a47da98d6c8a500d3e227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the training set\n",
    "train_input_ids = []\n",
    "train_attention_masks = []\n",
    "for text in tqdm(train_texts):\n",
    "    encoded_dict = tokenizer.encode_plus(text,\n",
    "                                         max_length=max_seq_length,\n",
    "                                         add_special_tokens=True,\n",
    "                                         truncation=True,\n",
    "                                         padding='max_length',\n",
    "                                         return_attention_mask=True,\n",
    "                                         return_tensors='pt')\n",
    "    train_input_ids.append(encoded_dict['input_ids'])\n",
    "    train_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:36.115766Z",
     "iopub.status.busy": "2024-05-17T17:25:36.115485Z",
     "iopub.status.idle": "2024-05-17T17:25:36.132249Z",
     "shell.execute_reply": "2024-05-17T17:25:36.131273Z",
     "shell.execute_reply.started": "2024-05-17T17:25:36.115739Z"
    },
    "id": "psYu3CJZruuU"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/3664121389.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_labels = torch.tensor(train_labels)\n"
     ]
    }
   ],
   "source": [
    "train_input_ids = torch.cat(train_input_ids, dim=0)\n",
    "train_attention_masks = torch.cat(train_attention_masks, dim=0)\n",
    "train_labels = torch.tensor(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:36.133869Z",
     "iopub.status.busy": "2024-05-17T17:25:36.133499Z",
     "iopub.status.idle": "2024-05-17T17:25:36.146100Z",
     "shell.execute_reply": "2024-05-17T17:25:36.145037Z",
     "shell.execute_reply.started": "2024-05-17T17:25:36.133833Z"
    },
    "id": "gPzgDcOsN2I0"
   },
   "outputs": [],
   "source": [
    "torch.save(train_input_ids, './train_input_ids_10lbls.pt')\n",
    "torch.save(train_attention_masks, './train_attention_masks_10lbls.pt')\n",
    "torch.save(train_labels, './train_labels_10lbls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "88b6262432f6429db0553c901e82e88e",
      "d3250d7e34644f6ca284376fdc850db5",
      "9f1f694f802a4e7f83725b3f6540f8ca",
      "b51b67a1f2b54a05ac84c02fd87b4dc8",
      "43968ef17ce94afc8f2f3e43ea465352",
      "e1b7668e6cae4706ad989273f33b8129",
      "3b96027dff0d4c38aa76ffc45659152a",
      "de94ad0aa2194e238149528472ab784f",
      "0c210400b3e1489ab4fda881e0207ec4",
      "0b8df0579bac470f8f2c6b0f2c002e9a",
      "55c26b04b8644ad99b03f20e01cdb82d"
     ]
    },
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:36.150044Z",
     "iopub.status.busy": "2024-05-17T17:25:36.149708Z",
     "iopub.status.idle": "2024-05-17T17:25:36.384293Z",
     "shell.execute_reply": "2024-05-17T17:25:36.383178Z",
     "shell.execute_reply.started": "2024-05-17T17:25:36.150015Z"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1684239233460,
     "user": {
      "displayName": "antoine magdi",
      "userId": "01891798323931301668"
     },
     "user_tz": -120
    },
    "id": "soiNyZ9FjfIw",
    "outputId": "2509e8fb-d568-4344-93df-58d63f49d75e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0298353a87244abf88f0680e45734e44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/253 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the validation set\n",
    "val_input_ids = []\n",
    "val_attention_masks = []\n",
    "for text in tqdm(val_texts):\n",
    "    encoded_dict = tokenizer.encode_plus(text,\n",
    "                                         max_length=max_seq_length,\n",
    "                                         add_special_tokens=True,\n",
    "                                         truncation=True,\n",
    "                                         padding='max_length',\n",
    "                                         return_attention_mask=True,\n",
    "                                         return_tensors='pt')\n",
    "    val_input_ids.append(encoded_dict['input_ids'])\n",
    "    val_attention_masks.append(encoded_dict['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:39.114981Z",
     "iopub.status.busy": "2024-05-17T17:25:39.114136Z",
     "iopub.status.idle": "2024-05-17T17:25:39.122901Z",
     "shell.execute_reply": "2024-05-17T17:25:39.121746Z",
     "shell.execute_reply.started": "2024-05-17T17:25:39.114945Z"
    },
    "id": "0Mo5uKOJsAZQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34/2405050284.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  val_labels = torch.tensor(val_labels)\n"
     ]
    }
   ],
   "source": [
    "val_input_ids = torch.cat(val_input_ids, dim=0)\n",
    "val_attention_masks = torch.cat(val_attention_masks, dim=0)\n",
    "val_labels = torch.tensor(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:39.527054Z",
     "iopub.status.busy": "2024-05-17T17:25:39.526096Z",
     "iopub.status.idle": "2024-05-17T17:25:39.534810Z",
     "shell.execute_reply": "2024-05-17T17:25:39.533721Z",
     "shell.execute_reply.started": "2024-05-17T17:25:39.527020Z"
    },
    "id": "nJOa5eM0xI3K"
   },
   "outputs": [],
   "source": [
    "# Save the tensors to files\n",
    "torch.save(val_input_ids, './val_input_ids_10lbls.pt')\n",
    "torch.save(val_attention_masks, './val_attention_masks_10lbls.pt')\n",
    "torch.save(val_labels, './val_labels_10lbls.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load checkpoints here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:40.980774Z",
     "iopub.status.busy": "2024-05-17T17:25:40.980070Z",
     "iopub.status.idle": "2024-05-17T17:25:40.989419Z",
     "shell.execute_reply": "2024-05-17T17:25:40.987976Z",
     "shell.execute_reply.started": "2024-05-17T17:25:40.980743Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import XLNetConfig, XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import DataCollatorWithPadding\n",
    "import string\n",
    "import pandas as pd\n",
    "import tqdm.notebook as tq\n",
    "import numpy as np\n",
    "from IPython.utils import io\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, Trainer, TrainingArguments, AdamW, get_linear_schedule_with_warmup\n",
    "from torch.utils.data import Dataset,TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import DataCollatorWithPadding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:41.657348Z",
     "iopub.status.busy": "2024-05-17T17:25:41.656493Z",
     "iopub.status.idle": "2024-05-17T17:25:41.667362Z",
     "shell.execute_reply": "2024-05-17T17:25:41.666278Z",
     "shell.execute_reply.started": "2024-05-17T17:25:41.657316Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/results/checkpoint-825'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "# Set the path to the directory containing the checkpoint folders\n",
    "checkpoint_dir = '/kaggle/working/results/'\n",
    "\n",
    "# Get a list of all the checkpoint folders in the directory\n",
    "checkpoint_folders = [f for f in os.listdir(checkpoint_dir) if re.match(r'checkpoint-\\d+', f)]\n",
    "\n",
    "# Sort the checkpoint folders by the numerical suffix\n",
    "checkpoint_folders.sort(key=lambda x: int(x.split('-')[-1]))\n",
    "\n",
    "# Get the latest checkpoint folder name\n",
    "latest_checkpoint_folder = os.path.join(checkpoint_dir, checkpoint_folders[-1])\n",
    "\n",
    "# Set the path to the checkpoint directory\n",
    "checkpoint_path = latest_checkpoint_folder\n",
    "checkpoint_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:42.747340Z",
     "iopub.status.busy": "2024-05-17T17:25:42.746892Z",
     "iopub.status.idle": "2024-05-17T17:25:42.759915Z",
     "shell.execute_reply": "2024-05-17T17:25:42.758354Z",
     "shell.execute_reply.started": "2024-05-17T17:25:42.747295Z"
    }
   },
   "outputs": [],
   "source": [
    "train_input_ids = torch.load('./train_input_ids_10lbls.pt')\n",
    "train_attention_masks = torch.load('./train_attention_masks_10lbls.pt')\n",
    "train_labels = torch.load('./train_labels_10lbls.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:43.260575Z",
     "iopub.status.busy": "2024-05-17T17:25:43.259953Z",
     "iopub.status.idle": "2024-05-17T17:25:43.268516Z",
     "shell.execute_reply": "2024-05-17T17:25:43.267399Z",
     "shell.execute_reply.started": "2024-05-17T17:25:43.260544Z"
    }
   },
   "outputs": [],
   "source": [
    "val_input_ids = torch.load('./val_input_ids_10lbls.pt')\n",
    "val_attention_masks = torch.load('./val_attention_masks_10lbls.pt')\n",
    "val_labels = torch.load('./val_labels_10lbls.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the XLNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:44.381487Z",
     "iopub.status.busy": "2024-05-17T17:25:44.380771Z",
     "iopub.status.idle": "2024-05-17T17:25:44.390033Z",
     "shell.execute_reply": "2024-05-17T17:25:44.389062Z",
     "shell.execute_reply.started": "2024-05-17T17:25:44.381452Z"
    }
   },
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, input_ids, attention_masks, labels):\n",
    "        self.input_ids = input_ids\n",
    "        self.attention_masks = attention_masks\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get the input_ids, attention_masks, and label tensors for the given index\n",
    "        input_id = self.input_ids[idx]\n",
    "        attention_mask = self.attention_masks[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_id,\n",
    "            'attention_mask': attention_mask,\n",
    "            'labels': label\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:44.891886Z",
     "iopub.status.busy": "2024-05-17T17:25:44.891284Z",
     "iopub.status.idle": "2024-05-17T17:25:44.897348Z",
     "shell.execute_reply": "2024-05-17T17:25:44.896273Z",
     "shell.execute_reply.started": "2024-05-17T17:25:44.891851Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a TensorDataset from the encoded texts and labels\n",
    "train_dataset = MyDataset(train_input_ids, train_attention_masks, train_labels)\n",
    "val_dataset = MyDataset(val_input_ids,val_attention_masks, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:25:45.388942Z",
     "iopub.status.busy": "2024-05-17T17:25:45.388589Z",
     "iopub.status.idle": "2024-05-17T17:25:48.322333Z",
     "shell.execute_reply": "2024-05-17T17:25:48.320567Z",
     "shell.execute_reply.started": "2024-05-17T17:25:45.388913Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 3003 has 15.87 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 65.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 22\u001b[0m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m      5\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      6\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./results\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     resume_from_checkpoint\u001b[38;5;241m=\u001b[39mcheckpoint_path\n\u001b[1;32m     20\u001b[0m )\n\u001b[0;32m---> 22\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDataCollatorWithPadding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:495\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    494\u001b[0m ):\n\u001b[0;32m--> 495\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:736\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 736\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2576\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2572\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2573\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2574\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2575\u001b[0m         )\n\u001b[0;32m-> 2576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacty of 15.89 GiB of which 22.12 MiB is free. Process 3003 has 15.87 GiB memory in use. Of the allocated memory 15.51 GiB is allocated by PyTorch, and 65.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "tokenizer = XLNetTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
    "model = XLNetForSequenceClassification.from_pretrained(\"xlnet-base-cased\", num_labels = num_labels)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=128,\n",
    "    per_device_eval_batch_size=128,\n",
    "    num_train_epochs=3,\n",
    "    warmup_steps=0,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=1000,\n",
    "    save_total_limit=3,\n",
    "    save_strategy='steps',\n",
    "    save_steps=1000,\n",
    "    resume_from_checkpoint=checkpoint_path\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-17T17:26:08.346404Z",
     "iopub.status.busy": "2024-05-17T17:26:08.345789Z",
     "iopub.status.idle": "2024-05-17T17:26:09.379478Z",
     "shell.execute_reply": "2024-05-17T17:26:09.378179Z",
     "shell.execute_reply.started": "2024-05-17T17:26:08.346370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 17 17:26:09 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   33C    P0              30W / 250W |  16254MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-05-17T17:25:48.323125Z",
     "iopub.status.idle": "2024-05-17T17:25:48.323504Z",
     "shell.execute_reply": "2024-05-17T17:25:48.323352Z",
     "shell.execute_reply.started": "2024-05-17T17:25:48.323338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fine-tune the model \n",
    "# WANDB API c07df26de2fdda62ae6c5019d4fe7dfd6aad0cc2\n",
    "trainer.train()\n",
    "eval_result = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T17:00:41.256821Z",
     "iopub.status.busy": "2024-05-15T17:00:41.255880Z",
     "iopub.status.idle": "2024-05-15T17:00:41.312423Z",
     "shell.execute_reply": "2024-05-15T17:00:41.309957Z",
     "shell.execute_reply.started": "2024-05-15T17:00:41.256786Z"
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Train labels are out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Check the range of the labels\u001b[39;00m\n\u001b[1;32m     10\u001b[0m n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(train_labels_np))\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m train_labels_np\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m train_labels_np\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m n_classes, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain labels are out of range\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m val_labels_np\u001b[38;5;241m.\u001b[39mmin() \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m val_labels_np\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;241m<\u001b[39m n_classes, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation labels are out of range\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Train labels are out of range"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'train_labels' and 'val_labels' are your label tensors\n",
    "\n",
    "# Convert to numpy arrays if they are not already\n",
    "train_labels_np = train_labels.numpy() if isinstance(train_labels, torch.Tensor) else np.array(train_labels)\n",
    "val_labels_np = val_labels.numpy() if isinstance(val_labels, torch.Tensor) else np.array(val_labels)\n",
    "\n",
    "# Check the range of the labels\n",
    "n_classes = len(np.unique(train_labels_np))\n",
    "assert train_labels_np.min() >= 0 and train_labels_np.max() < n_classes, \"Train labels are out of range\"\n",
    "assert val_labels_np.min() >= 0 and val_labels_np.max() < n_classes, \"Validation labels are out of range\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-15T17:01:19.948227Z",
     "iopub.status.busy": "2024-05-15T17:01:19.947850Z",
     "iopub.status.idle": "2024-05-15T17:01:19.959015Z",
     "shell.execute_reply": "2024-05-15T17:01:19.958082Z",
     "shell.execute_reply.started": "2024-05-15T17:01:19.948198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique train labels: [ 0  1  3  4  5  6  7  8  9 10]\n",
      "Unique validation labels: [ 0  1  3  4  5  6  7  8  9 10]\n"
     ]
    }
   ],
   "source": [
    "# Inspect unique label values\n",
    "print(\"Unique train labels:\", np.unique(train_labels_np))\n",
    "print(\"Unique validation labels:\", np.unique(val_labels_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4974860,
     "sourceId": 8393697,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
